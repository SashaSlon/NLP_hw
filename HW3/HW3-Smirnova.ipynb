{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LALHxpyfTl_K"
   },
   "source": [
    "# Тестирование TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-loWsYdUTl_M"
   },
   "source": [
    "Устанавливаем TreeTagger:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4295,
     "status": "ok",
     "timestamp": 1560539971100,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "4BrZ8tLHUhb-",
    "outputId": "1e731378-3acf-4617-b0e5-02be78581033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-14 19:19:33--  http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.2.tar.gz\n",
      "Resolving www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
      "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.2.tar.gz [following]\n",
      "--2019-06-14 19:19:33--  https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.2.tar.gz\n",
      "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1821366 (1.7M) [application/x-gzip]\n",
      "Saving to: ‘tree-tagger-linux-3.2.2.tar.gz’\n",
      "\n",
      "tree-tagger-linux-3 100%[===================>]   1.74M  2.69MB/s    in 0.6s    \n",
      "\n",
      "2019-06-14 19:19:34 (2.69 MB/s) - ‘tree-tagger-linux-3.2.2.tar.gz’ saved [1821366/1821366]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.2.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2433,
     "status": "ok",
     "timestamp": 1560539988901,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "B_udh52LUjoS",
    "outputId": "6f2431ae-fa3d-42fd-fe63-61ab0c17ba2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-14 19:19:51--  http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
      "Resolving www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
      "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz [following]\n",
      "--2019-06-14 19:19:52--  https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
      "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 101810 (99K) [application/x-gzip]\n",
      "Saving to: ‘tagger-scripts.tar.gz’\n",
      "\n",
      "tagger-scripts.tar. 100%[===================>]  99.42K   463KB/s    in 0.2s    \n",
      "\n",
      "2019-06-14 19:19:52 (463 KB/s) - ‘tagger-scripts.tar.gz’ saved [101810/101810]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2261,
     "status": "ok",
     "timestamp": 1560539991837,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "3K-QKkBHUljE",
    "outputId": "08b7570e-5e06-42b0-c817-de0c9c99e4b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-14 19:19:54--  http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
      "Resolving www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
      "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/install-tagger.sh [following]\n",
      "--2019-06-14 19:19:54--  https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
      "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12417 (12K) [application/x-shellscript]\n",
      "Saving to: ‘install-tagger.sh’\n",
      "\n",
      "install-tagger.sh   100%[===================>]  12.13K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-06-14 19:19:55 (182 MB/s) - ‘install-tagger.sh’ saved [12417/12417]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7034,
     "status": "ok",
     "timestamp": 1560539999683,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "O7nhrHyAUnqR",
    "outputId": "dd5da677-a8d0-41fb-9d7e-c5ce2cacb81e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-14 19:19:57--  http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/russian.par.gz\n",
      "Resolving www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
      "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/russian.par.gz [following]\n",
      "--2019-06-14 19:19:58--  https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/russian.par.gz\n",
      "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 115748255 (110M) [application/x-gzip]\n",
      "Saving to: ‘russian.par.gz’\n",
      "\n",
      "russian.par.gz      100%[===================>] 110.39M  27.4MB/s    in 4.7s    \n",
      "\n",
      "2019-06-14 19:20:03 (23.3 MB/s) - ‘russian.par.gz’ saved [115748255/115748255]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/russian.par.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4603,
     "status": "ok",
     "timestamp": 1560540004981,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "w5amsS6FUqTw",
    "outputId": "5f37e6f6-8a50-46a6-cf53-b852e0f07b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TreeTagger version for PC-Linux installed.\n",
      "Tagging scripts installed.\n",
      "Russian parameter file installed.\n",
      "Path variables modified in tagging scripts.\n",
      "\n",
      "You might want to add /content/cmd and /content/bin to the PATH variable so that you do not need to specify the full path to run the tagging scripts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sh install-tagger.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4890,
     "status": "ok",
     "timestamp": 1560528618967,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "Aubz77JoUs7s",
    "outputId": "b580dfed-8d6f-48dc-f7da-d0efff943d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "Я\tP-1-snn\tя\n",
      "хочу\tVmip1s-a-e\tхотеть\n",
      "съесть\tVmn----a-p\tсъесть\n",
      "яблоко\tNcnsan\tяблоко\n",
      "!\tSENT\t!\n",
      "\t finished.\n"
     ]
    }
   ],
   "source": [
    "!echo 'Я хочу съесть яблоко!' | cmd/tree-tagger-russian \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hB-xWt7wwTEt"
   },
   "source": [
    "**Распаковываем корпус**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2585,
     "status": "ok",
     "timestamp": 1560540010000,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "kwIzT86sUuRZ",
    "outputId": "bc6be6df-b271-49a2-c2a2-5a5c164a9e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-14 19:20:12--  http://opencorpora.org/files/export/annot/annot.opcorpora.no_ambig_strict.xml.zip\n",
      "Resolving opencorpora.org (opencorpora.org)... 148.251.2.141\n",
      "Connecting to opencorpora.org (opencorpora.org)|148.251.2.141|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2194522 (2.1M) [application/zip]\n",
      "Saving to: ‘annot.opcorpora.no_ambig_strict.xml.zip’\n",
      "\n",
      "annot.opcorpora.no_ 100%[===================>]   2.09M  2.89MB/s    in 0.7s    \n",
      "\n",
      "2019-06-14 19:20:13 (2.89 MB/s) - ‘annot.opcorpora.no_ambig_strict.xml.zip’ saved [2194522/2194522]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://opencorpora.org/files/export/annot/annot.opcorpora.no_ambig_strict.xml.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2481,
     "status": "ok",
     "timestamp": 1560540014014,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "JBV8mclocW9H",
    "outputId": "1d6bbf33-3a33-4727-e062-a2ff8fc1e2b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  annot.opcorpora.no_ambig_strict.xml.zip\n",
      "  inflating: annot.opcorpora.no_ambig_strict.xml  \n"
     ]
    }
   ],
   "source": [
    "!unzip annot.opcorpora.no_ambig_strict.xml.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5717,
     "status": "ok",
     "timestamp": 1560540025679,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "092ne85sLqha",
    "outputId": "2bfb0d7b-e306-4555-c90a-aecb133de404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
      "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4 (from pymorphy2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1MB 8.8MB/s \n",
      "\u001b[?25hCollecting dawg-python>=0.7 (from pymorphy2)\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
      "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKKfQ0csLYf_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lxml import etree\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wX-Ajl7Tl_a"
   },
   "outputs": [],
   "source": [
    "corpora = etree.fromstring(open('annot.opcorpora.no_ambig_strict.xml', 'rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsGmWbA2Tl_f"
   },
   "source": [
    "**Перезапишем корпус в переменную corpus. Создадим массив кортежей (форматированое предложение для обучение, стандартное предложение для теста, верный грамматический разбор)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuHFMQN0Tl_g"
   },
   "outputs": [],
   "source": [
    "vocab = defaultdict(set)\n",
    "tags = set()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for sentence in corpora.xpath('//tokens'):\n",
    "    formatted_sent = \"\"\n",
    "    standart_sent = []\n",
    "    gram_infos = []\n",
    "    length = len(sentence.xpath('token'))\n",
    "    ended = False\n",
    "    for i,token in enumerate(sentence.xpath('token')):\n",
    "        word = token.xpath('@text')\n",
    "        gram_info = token.xpath('tfr/v/l/g/@v')\n",
    "        if (i + 1) == length and gram_info[0] == 'PNCT':\n",
    "            gram_info = ['SENT']\n",
    "            ended = True\n",
    "        formatted_sent += word[0] + '\\t' + ','.join(gram_info) + '\\n'\n",
    "        standart_sent.append(word[0])\n",
    "        lemma = token.xpath('tfr/v/l/@t')[0]\n",
    "        vocab[word[0].lower()].add((','.join(gram_info), lemma.lower()))\n",
    "        tags.add(','.join(gram_info))\n",
    "        gram_infos.append((word[0], gram_info))\n",
    "    if not ended:\n",
    "        formatted_sent += '.\\tSENT\\n'\n",
    "    standart_sent = \" \".join(standart_sent)\n",
    "    corpus.append((formatted_sent, standart_sent, gram_infos))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q8I_RcctMOnK"
   },
   "source": [
    "Проверим, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1560540040247,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "qidMo7PMMMny",
    "outputId": "785b4581-0b05-4325-95c9-11e1d04dcf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "длина корпуса:  10599\n"
     ]
    }
   ],
   "source": [
    "print(\"длина корпуса: \", str(len(corpus)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1560540045318,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "5JPwhgYcMaYp",
    "outputId": "40531c5c-2ae8-423d-e48d-12611135a540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('«\\tPNCT\\nШкола\\tNOUN,inan,femn,sing,nomn\\nзлословия\\tNOUN,inan,neut,sing,gent\\n»\\tPNCT\\nучит\\tVERB,impf,tran,sing,3per,pres,indc\\nприкусить\\tINFN,perf,tran\\nязык\\tNOUN,inan,masc,sing,accs\\n.\\tSENT\\n', '« Школа злословия » учит прикусить язык', [('«', ['PNCT']), ('Школа', ['NOUN', 'inan', 'femn', 'sing', 'nomn']), ('злословия', ['NOUN', 'inan', 'neut', 'sing', 'gent']), ('»', ['PNCT']), ('учит', ['VERB', 'impf', 'tran', 'sing', '3per', 'pres', 'indc']), ('прикусить', ['INFN', 'perf', 'tran']), ('язык', ['NOUN', 'inan', 'masc', 'sing', 'accs'])])\n",
      "('Сохранится\\tVERB,perf,intr,sing,3per,futr,indc\\nли\\tPRCL\\nградус\\tNOUN,inan,masc,sing,nomn\\nдискуссии\\tNOUN,inan,femn,sing,gent\\nв\\tPREP\\nновом\\tADJF,Qual,masc,sing,loct\\nсезоне\\tNOUN,inan,masc,sing,loct\\n?\\tSENT\\n', 'Сохранится ли градус дискуссии в новом сезоне ?', [('Сохранится', ['VERB', 'perf', 'intr', 'sing', '3per', 'futr', 'indc']), ('ли', ['PRCL']), ('градус', ['NOUN', 'inan', 'masc', 'sing', 'nomn']), ('дискуссии', ['NOUN', 'inan', 'femn', 'sing', 'gent']), ('в', ['PREP']), ('новом', ['ADJF', 'Qual', 'masc', 'sing', 'loct']), ('сезоне', ['NOUN', 'inan', 'masc', 'sing', 'loct']), ('?', ['SENT'])])\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qpF08Vg5Tl_l"
   },
   "outputs": [],
   "source": [
    "with open('lexicon.txt', 'a', encoding='utf-8') as f1:\n",
    "  for word in vocab:\n",
    "      line = word + '\\t'\n",
    "      pos_tags = '\\t'.join([' '.join(pair) for pair in vocab[word]])\n",
    "      f1.write(line+pos_tags+'\\n')\n",
    "\n",
    "with open('open_class.txt', 'a', encoding='utf-8') as f2:\n",
    "  f2.write('\\n'.join([tag for tag in tags if 'NOUN' in tag or 'VERB' in tag or 'ADJF' in tag]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fzlYPj7GNJDl"
   },
   "source": [
    "В файле lexicon.txt получили таблицу \"словоформа-PoStags-лемма\", в файле open_class.txt - подробный список PoS-тэгов для каждого открытого класса слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1560540049639,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "joZM2JtGnGnu",
    "outputId": "5078c630-84be-4b2a-c8b4-57a8e7a6de51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['«\\tPNCT «\\n', 'школа\\tNOUN,inan,femn,sing,nomn школа\\n', 'злословия\\tNOUN,inan,neut,sing,gent злословие\\n']\n",
      "['ADJF,Subx,Qual,plur,nomn\\n', 'NOUN,inan,neut,sing,nomn,V-be\\n', 'NOUN,inan,femn,Inmx,plur,nomn\\n']\n"
     ]
    }
   ],
   "source": [
    "with open('lexicon.txt', 'r', encoding='utf-8') as f3:\n",
    "  text = f3.readlines()\n",
    "  print(text[:3])\n",
    "with open('open_class.txt', 'r', encoding='utf-8') as f4:\n",
    "  text = f4.readlines()\n",
    "  print(text[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYpkynmmNaG9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJUqKwf_AwiG"
   },
   "source": [
    "Разбиваем выборку на 10 обучающих частей для кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1K8Js3qoohzy"
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XpTlijU9HPP"
   },
   "outputs": [],
   "source": [
    "c_v_folds = []\n",
    "for i in range(len(corpus)):\n",
    "    c_v_folds.append(corpus[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1y2czIn9kjM"
   },
   "outputs": [],
   "source": [
    "cross_val_folds = list(chunks(c_v_folds, 1060))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1560540061374,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "jBhUia0l928r",
    "outputId": "6d87a2fd-a324-487a-ae3f-a016e6f5eaef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(cross_val_folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYZFajFuTl_v"
   },
   "outputs": [],
   "source": [
    "def true_pos_finder(cv_fold):\n",
    "  '''Функция для определения ошибки: сравнивает предсказанный \n",
    "     результат с истинным и возвращает массив из нулей и единиц.'''\n",
    "    pos = []\n",
    "    for sent in cv_fold:\n",
    "        for word in sent[2]:\n",
    "            pos.append((word[0], word[1][0]))\n",
    "    return pos\n",
    "\n",
    "def predicted_pos_finder(f_name):\n",
    "  '''Функция для парсинга выхода модели: \n",
    "     возвращает массив предсказанных частей речи.'''\n",
    "    with open(f_name, 'r') as fd:\n",
    "        content = fd.read()\n",
    "    content = content.split(\"\\n\")\n",
    "    pos = []\n",
    "    for w in content:\n",
    "        if len(w) != 0:\n",
    "            pos.append(w.split(',')[0])\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5moHfywhTl_0"
   },
   "outputs": [],
   "source": [
    "MISTAKES = Counter()\n",
    "\n",
    "def mistake_finder(output_filename, cross_val_fold):\n",
    "  '''функция для нахождения ошибок и выявления их реальных соответствий.\n",
    "     Выдает в аутпуте счетчик, показывающий частотность ошибок для каждой конкретной лексемы'''\n",
    "    fold_mistake = Counter()\n",
    "    score = []\n",
    "    predicted = predicted_pos_finder(output_filename)\n",
    "    true = true_pos_finder(cross_val_fold)\n",
    "    for pos in range(len(predicted)):\n",
    "        try:\n",
    "            if predicted[pos] == true[pos][1]:\n",
    "                score.append(1)\n",
    "            else:\n",
    "                MISTAKES.update([(true[pos][0], true[pos][1], predicted[pos])])\n",
    "                fold_mistake.update([(true[pos][0], true[pos][1], predicted[pos])])\n",
    "                score.append(0)\n",
    "        except IndexError:\n",
    "            sys.exit(0)\n",
    "    return (score, fold_mistake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6c1IhcgDrpw7"
   },
   "source": [
    "**Прогоним наш счетчик по фолдам**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4658
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 153317,
     "status": "ok",
     "timestamp": 1560540221546,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "KMaa0bd-Tl_5",
    "outputId": "cf589bee-523c-427f-ec0c-b03d1c4639d4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'corpus_train.txt': No such file or directory\n",
      "rm: cannot remove 'corpus_test.txt': No such file or directory\n",
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "50000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1799 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "62938\t30755\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "86\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 87\n",
      "Max. path length: 15\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:14<02:06, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "\r",
      "1000\r",
      "2000\r",
      "3000\r",
      "4000\r",
      "5000\r",
      "6000\r",
      "7000\r",
      "8000\r",
      "9000\r",
      "10000\r",
      "11000\r",
      "12000\r",
      "13000\r",
      "14000\r",
      "15000\r",
      "16000\r",
      "17000\r",
      "18000\r",
      "19000\r",
      "20000\r",
      "21000\r",
      "22000\r",
      "23000\r",
      "24000\r",
      "25000\r",
      "26000\r",
      "27000\r",
      "28000\r",
      "29000\r",
      "30000\r",
      "31000\r",
      "32000\r",
      "33000\r",
      "34000\r",
      "35000\r",
      "36000\r",
      "37000\r",
      "38000\r",
      "39000\r",
      "40000\r",
      "41000\r",
      "42000\r",
      "43000\r",
      "44000\r",
      "45000\r",
      "46000\r",
      "47000\r",
      "48000\r",
      "49000\r",
      "50000\r",
      "51000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1794 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "\r",
      "1000\t783\r",
      "2000\t1407\r",
      "3000\t2056\r",
      "4000\t2723\r",
      "5000\t3370\r",
      "6000\t3798\r",
      "7000\t4329\r",
      "8000\t4902\r",
      "9000\t5546\r",
      "10000\t6172\r",
      "11000\t6786\r",
      "12000\t7341\r",
      "13000\t7727\r",
      "14000\t8127\r",
      "15000\t8662\r",
      "16000\t9198\r",
      "17000\t9704\r",
      "18000\t10171\r",
      "19000\t10644\r",
      "20000\t11131\r",
      "21000\t11618\r",
      "22000\t12078\r",
      "23000\t12574\r",
      "24000\t12993\r",
      "25000\t13466\r",
      "26000\t14012\r",
      "27000\t14355\r",
      "28000\t14598\r",
      "29000\t15015\r",
      "30000\t15379\r",
      "31000\t15837\r",
      "32000\t16266\r",
      "33000\t16846\r",
      "34000\t17398\r",
      "35000\t17909\r",
      "36000\t18289\r",
      "37000\t18668\r",
      "38000\t19110\r",
      "39000\t19602\r",
      "40000\t20111\r",
      "41000\t20630\r",
      "42000\t21115\r",
      "43000\t21637\r",
      "44000\t22130\r",
      "45000\t22579\r",
      "46000\t23062\r",
      "47000\t23560\r",
      "48000\t24080\r",
      "49000\t24481\r",
      "50000\t24989\r",
      "51000\t25473\r",
      "52000\t25984\r",
      "53000\t26415\r",
      "54000\t26865\r",
      "55000\t27325\r",
      "56000\t27789\r",
      "57000\t28215\r",
      "58000\t28654\r",
      "59000\t29106\r",
      "60000\t29406\r",
      "61000\t29841\r",
      "62000\t30225\r",
      "63000\t30567\r",
      "63337\t30698\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "94\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 95\n",
      "Max. path length: 16\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:28<01:53, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "\r",
      "1000\r",
      "2000\r",
      "3000\r",
      "4000\r",
      "5000\r",
      "6000\r",
      "7000\r",
      "8000\r",
      "9000\r",
      "10000\r",
      "11000\r",
      "12000\r",
      "13000\r",
      "14000\r",
      "15000\r",
      "16000\r",
      "17000\r",
      "18000\r",
      "19000\r",
      "20000\r",
      "21000\r",
      "22000\r",
      "23000\r",
      "24000\r",
      "25000\r",
      "26000\r",
      "27000\r",
      "28000\r",
      "29000\r",
      "30000\r",
      "31000\r",
      "32000\r",
      "33000\r",
      "34000\r",
      "35000\r",
      "36000\r",
      "37000\r",
      "38000\r",
      "39000\r",
      "40000\r",
      "41000\r",
      "42000\r",
      "43000\r",
      "44000\r",
      "45000\r",
      "46000\r",
      "47000\r",
      "48000\r",
      "49000\r",
      "50000\r",
      "51000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1790 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "\r",
      "1000\t783\r",
      "2000\t1407\r",
      "3000\t2056\r",
      "4000\t2723\r",
      "5000\t3370\r",
      "6000\t3798\r",
      "7000\t4329\r",
      "8000\t4902\r",
      "9000\t5546\r",
      "10000\t6172\r",
      "11000\t6786\r",
      "12000\t7341\r",
      "13000\t7727\r",
      "14000\t8127\r",
      "15000\t8662\r",
      "16000\t9198\r",
      "17000\t9704\r",
      "18000\t10171\r",
      "19000\t10644\r",
      "20000\t11131\r",
      "21000\t11618\r",
      "22000\t12078\r",
      "23000\t12574\r",
      "24000\t12993\r",
      "25000\t13466\r",
      "26000\t14012\r",
      "27000\t14355\r",
      "28000\t14598\r",
      "29000\t15015\r",
      "30000\t15379\r",
      "31000\t15837\r",
      "32000\t16266\r",
      "33000\t16846\r",
      "34000\t17398\r",
      "35000\t17909\r",
      "36000\t18289\r",
      "37000\t18668\r",
      "38000\t19110\r",
      "39000\t19602\r",
      "40000\t20111\r",
      "41000\t20630\r",
      "42000\t21115\r",
      "43000\t21637\r",
      "44000\t22130\r",
      "45000\t22579\r",
      "46000\t23062\r",
      "47000\t23554\r",
      "48000\t24039\r",
      "49000\t24499\r",
      "50000\t24959\r",
      "51000\t25464\r",
      "52000\t25901\r",
      "53000\t26425\r",
      "54000\t26779\r",
      "55000\t27197\r",
      "56000\t27669\r",
      "57000\t28095\r",
      "58000\t28528\r",
      "59000\t28970\r",
      "60000\t29282\r",
      "61000\t29704\r",
      "62000\t30101\r",
      "63000\t30436\r",
      "63098\t30477\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "92\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 93\n",
      "Max. path length: 16\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:42<01:39, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "\r",
      "1000\r",
      "2000\r",
      "3000\r",
      "4000\r",
      "5000\r",
      "6000\r",
      "7000\r",
      "8000\r",
      "9000\r",
      "10000\r",
      "11000\r",
      "12000\r",
      "13000\r",
      "14000\r",
      "15000\r",
      "16000\r",
      "17000\r",
      "18000\r",
      "19000\r",
      "20000\r",
      "21000\r",
      "22000\r",
      "23000\r",
      "24000\r",
      "25000\r",
      "26000\r",
      "27000\r",
      "28000\r",
      "29000\r",
      "30000\r",
      "31000\r",
      "32000\r",
      "33000\r",
      "34000\r",
      "35000\r",
      "36000\r",
      "37000\r",
      "38000\r",
      "39000\r",
      "40000\r",
      "41000\r",
      "42000\r",
      "43000\r",
      "44000\r",
      "45000\r",
      "46000\r",
      "47000\r",
      "48000\r",
      "49000\r",
      "50000\r",
      "51000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1787 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "\r",
      "1000\t783\r",
      "2000\t1407\r",
      "3000\t2056\r",
      "4000\t2723\r",
      "5000\t3370\r",
      "6000\t3798\r",
      "7000\t4329\r",
      "8000\t4902\r",
      "9000\t5546\r",
      "10000\t6172\r",
      "11000\t6786\r",
      "12000\t7341\r",
      "13000\t7727\r",
      "14000\t8127\r",
      "15000\t8662\r",
      "16000\t9198\r",
      "17000\t9704\r",
      "18000\t10171\r",
      "19000\t10644\r",
      "20000\t11131\r",
      "21000\t11618\r",
      "22000\t12078\r",
      "23000\t12574\r",
      "24000\t12993\r",
      "25000\t13466\r",
      "26000\t14012\r",
      "27000\t14355\r",
      "28000\t14598\r",
      "29000\t15015\r",
      "30000\t15379\r",
      "31000\t15837\r",
      "32000\t16266\r",
      "33000\t16846\r",
      "34000\t17398\r",
      "35000\t17909\r",
      "36000\t18289\r",
      "37000\t18668\r",
      "38000\t19110\r",
      "39000\t19620\r",
      "40000\t20132\r",
      "41000\t20577\r",
      "42000\t21105\r",
      "43000\t21647\r",
      "44000\t22164\r",
      "45000\t22642\r",
      "46000\t23116\r",
      "47000\t23586\r",
      "48000\t24066\r",
      "49000\t24527\r",
      "50000\t24980\r",
      "51000\t25471\r",
      "52000\t25916\r",
      "53000\t26426\r",
      "54000\t26785\r",
      "55000\t27197\r",
      "56000\t27655\r",
      "57000\t28080\r",
      "58000\t28526\r",
      "59000\t28966\r",
      "60000\t29270\r",
      "61000\t29697\r",
      "62000\t30090\r",
      "63000\t30427\r",
      "63085\t30465\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "100\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 101\n",
      "Max. path length: 16\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:58<01:28, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "\r",
      "1000\r",
      "2000\r",
      "3000\r",
      "4000\r",
      "5000\r",
      "6000\r",
      "7000\r",
      "8000\r",
      "9000\r",
      "10000\r",
      "11000\r",
      "12000\r",
      "13000\r",
      "14000\r",
      "15000\r",
      "16000\r",
      "17000\r",
      "18000\r",
      "19000\r",
      "20000\r",
      "21000\r",
      "22000\r",
      "23000\r",
      "24000\r",
      "25000\r",
      "26000\r",
      "27000\r",
      "28000\r",
      "29000\r",
      "30000\r",
      "31000\r",
      "32000\r",
      "33000\r",
      "34000\r",
      "35000\r",
      "36000\r",
      "37000\r",
      "38000\r",
      "39000\r",
      "40000\r",
      "41000\r",
      "42000\r",
      "43000\r",
      "44000\r",
      "45000\r",
      "46000\r",
      "47000\r",
      "48000\r",
      "49000\r",
      "50000\r",
      "51000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1791 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "\r",
      "1000\t783\r",
      "2000\t1407\r",
      "3000\t2056\r",
      "4000\t2723\r",
      "5000\t3370\r",
      "6000\t3798\r",
      "7000\t4329\r",
      "8000\t4902\r",
      "9000\t5546\r",
      "10000\t6172\r",
      "11000\t6786\r",
      "12000\t7341\r",
      "13000\t7727\r",
      "14000\t8127\r",
      "15000\t8662\r",
      "16000\t9198\r",
      "17000\t9704\r",
      "18000\t10171\r",
      "19000\t10644\r",
      "20000\t11131\r",
      "21000\t11618\r",
      "22000\t12078\r",
      "23000\t12574\r",
      "24000\t12993\r",
      "25000\t13466\r",
      "26000\t14012\r",
      "27000\t14355\r",
      "28000\t14598\r",
      "29000\t15015\r",
      "30000\t15379\r",
      "31000\t15873\r",
      "32000\t16426\r",
      "33000\t16975\r",
      "34000\t17496\r",
      "35000\t18064\r",
      "36000\t18584\r",
      "37000\t19060\r",
      "38000\t19571\r",
      "39000\t20099\r",
      "40000\t20651\r",
      "41000\t21081\r",
      "42000\t21617\r",
      "43000\t22119\r",
      "44000\t22661\r",
      "45000\t23107\r",
      "46000\t23569\r",
      "47000\t24052\r",
      "48000\t24537\r",
      "49000\t24990\r",
      "50000\t25457\r",
      "51000\t25938\r",
      "52000\t26394\r",
      "53000\t26909\r",
      "54000\t27288\r",
      "55000\t27687\r",
      "56000\t28143\r",
      "57000\t28570\r",
      "58000\t29004\r",
      "59000\t29442\r",
      "60000\t29743\r",
      "61000\t30186\r",
      "62000\t30563\r",
      "63000\t30899\r",
      "63247\t31010\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "88\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 89\n",
      "Max. path length: 14\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "7000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [01:12<01:12, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "\r",
      "1000\r",
      "2000\r",
      "3000\r",
      "4000\r",
      "5000\r",
      "6000\r",
      "7000\r",
      "8000\r",
      "9000\r",
      "10000\r",
      "11000\r",
      "12000\r",
      "13000\r",
      "14000\r",
      "15000\r",
      "16000\r",
      "17000\r",
      "18000\r",
      "19000\r",
      "20000\r",
      "21000\r",
      "22000\r",
      "23000\r",
      "24000\r",
      "25000\r",
      "26000\r",
      "27000\r",
      "28000\r",
      "29000\r",
      "30000\r",
      "31000\r",
      "32000\r",
      "33000\r",
      "34000\r",
      "35000\r",
      "36000\r",
      "37000\r",
      "38000\r",
      "39000\r",
      "40000\r",
      "41000\r",
      "42000\r",
      "43000\r",
      "44000\r",
      "45000\r",
      "46000\r",
      "47000\r",
      "48000\r",
      "49000\r",
      "50000\r",
      "51000\r",
      "52000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1790 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "\r",
      "1000\t783\r",
      "2000\t1407\r",
      "3000\t2056\r",
      "4000\t2723\r",
      "5000\t3370\r",
      "6000\t3798\r",
      "7000\t4329\r",
      "8000\t4902\r",
      "9000\t5546\r",
      "10000\t6172\r",
      "11000\t6786\r",
      "12000\t7341\r",
      "13000\t7727\r",
      "14000\t8127\r",
      "15000\t8662\r",
      "16000\t9198\r",
      "17000\t9704\r",
      "18000\t10171\r",
      "19000\t10644\r",
      "20000\t11131\r",
      "21000\t11618\r",
      "22000\t12078\r",
      "23000\t12574\r",
      "24000\t13012\r",
      "25000\t13476\r",
      "26000\t14030\r",
      "27000\t14650\r",
      "28000\t15151\r",
      "29000\t15613\r",
      "30000\t16066\r",
      "31000\t16462\r",
      "32000\t16968\r",
      "33000\t17480\r",
      "34000\t18031\r",
      "35000\t18557\r",
      "36000\t19084\r",
      "37000\t19613\r",
      "38000\t20100\r",
      "39000\t20578\r",
      "40000\t21085\r",
      "41000\t21618\r",
      "42000\t22031\r",
      "43000\t22539\r",
      "44000\t23045\r",
      "45000\t23574\r",
      "46000\t24075\r",
      "47000\t24479\r",
      "48000\t24972\r",
      "49000\t25442\r",
      "50000\t25913\r",
      "51000\t26373\r",
      "52000\t26830\r",
      "53000\t27259\r",
      "54000\t27760\r",
      "55000\t28141\r",
      "56000\t28568\r",
      "57000\t28961\r",
      "58000\t29426\r",
      "59000\t29837\r",
      "60000\t30264\r",
      "61000\t30688\r",
      "62000\t30974\r",
      "63000\t31382\r",
      "64000\t31739\r",
      "64812\t32031\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "80\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 81\n",
      "Max. path length: 15\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "6000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [01:27<00:58, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "\r",
      "1000\r",
      "2000\r",
      "3000\r",
      "4000\r",
      "5000\r",
      "6000\r",
      "7000\r",
      "8000\r",
      "9000\r",
      "10000\r",
      "11000\r",
      "12000\r",
      "13000\r",
      "14000\r",
      "15000\r",
      "16000\r",
      "17000\r",
      "18000\r",
      "19000\r",
      "20000\r",
      "21000\r",
      "22000\r",
      "23000\r",
      "24000\r",
      "25000\r",
      "26000\r",
      "27000\r",
      "28000\r",
      "29000\r",
      "30000\r",
      "31000\r",
      "32000\r",
      "33000\r",
      "34000\r",
      "35000\r",
      "36000\r",
      "37000\r",
      "38000\r",
      "39000\r",
      "40000\r",
      "41000\r",
      "42000\r",
      "43000\r",
      "44000\r",
      "45000\r",
      "46000\r",
      "47000\r",
      "48000\r",
      "49000\r",
      "50000\r",
      "51000\r",
      "52000\tmaking affix tree ...\n",
      "prefix lexicon: 806 nodes\n",
      "suffix lexicon: 1791 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "\r",
      "1000\t783\r",
      "2000\t1407\r",
      "3000\t2056\r",
      "4000\t2723\r",
      "5000\t3370\r",
      "6000\t3798\r",
      "7000\t4329\r",
      "8000\t4902\r",
      "9000\t5546\r",
      "10000\t6172\r",
      "11000\t6786\r",
      "12000\t7341\r",
      "13000\t7727\r",
      "14000\t8127\r",
      "15000\t8662\r",
      "16000\t9198\r",
      "17000\t9704\r",
      "18000\t10098\r",
      "19000\t10721\r",
      "20000\t11210\r",
      "21000\t11478\r",
      "22000\t11872\r",
      "23000\t12270\r",
      "24000\t12658\r",
      "25000\t13127\r",
      "26000\t13688\r",
      "27000\t14304\r",
      "28000\t14812\r",
      "29000\t15277\r",
      "30000\t15739\r",
      "31000\t16107\r",
      "32000\t16607\r",
      "33000\t17107\r",
      "34000\t17667\r",
      "35000\t18209\r",
      "36000\t18726\r",
      "37000\t19266\r",
      "38000\t19752\r",
      "39000\t20229\r",
      "40000\t20753\r",
      "41000\t21281\r",
      "42000\t21700\r",
      "43000\t22210\r",
      "44000\t22701\r",
      "45000\t23250\r",
      "46000\t23745\r",
      "47000\t24164\r",
      "48000\t24651\r",
      "49000\t25115\r",
      "50000\t25589\r",
      "51000\t26047\r",
      "52000\t26517\r",
      "53000\t26952\r",
      "54000\t27437\r",
      "55000\t27814\r",
      "56000\t28236\r",
      "57000\t28638\r",
      "58000\t29106\r",
      "59000\t29510\r",
      "60000\t29944\r",
      "61000\t30360\r",
      "62000\t30658\r",
      "63000\t31064\r",
      "64000\t31446\r",
      "64758\t31710\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "88\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 89\n",
      "Max. path length: 15\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "5000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [01:42<00:44, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "\r",
      "1000\r",
      "2000\r",
      "3000\r",
      "4000\r",
      "5000\r",
      "6000\r",
      "7000\r",
      "8000\r",
      "9000\r",
      "10000\r",
      "11000\r",
      "12000\r",
      "13000\r",
      "14000\r",
      "15000\r",
      "16000\r",
      "17000\r",
      "18000\r",
      "19000\r",
      "20000\r",
      "21000\r",
      "22000\r",
      "23000\r",
      "24000\r",
      "25000\r",
      "26000\r",
      "27000\r",
      "28000\r",
      "29000\r",
      "30000\r",
      "31000\r",
      "32000\r",
      "33000\r",
      "34000\r",
      "35000\r",
      "36000\r",
      "37000\r",
      "38000\r",
      "39000\r",
      "40000\r",
      "41000\r",
      "42000\r",
      "43000\r",
      "44000\r",
      "45000\r",
      "46000\r",
      "47000\r",
      "48000\r",
      "49000\r",
      "50000\r",
      "51000\r",
      "52000\r",
      "53000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1791 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "\r",
      "1000\t783\r",
      "2000\t1407\r",
      "3000\t2056\r",
      "4000\t2723\r",
      "5000\t3370\r",
      "6000\t3798\r",
      "7000\t4329\r",
      "8000\t4902\r",
      "9000\t5546\r",
      "10000\t6172\r",
      "11000\t6786\r",
      "12000\t7339\r",
      "13000\t7885\r",
      "14000\t8379\r",
      "15000\t8874\r",
      "16000\t9421\r",
      "17000\t9954\r",
      "18000\t10435\r",
      "19000\t10839\r",
      "20000\t11450\r",
      "21000\t11947\r",
      "22000\t12229\r",
      "23000\t12585\r",
      "24000\t12969\r",
      "25000\t13357\r",
      "26000\t13818\r",
      "27000\t14371\r",
      "28000\t14976\r",
      "29000\t15499\r",
      "30000\t15972\r",
      "31000\t16427\r",
      "32000\t16809\r",
      "33000\t17273\r",
      "34000\t17754\r",
      "35000\t18297\r",
      "36000\t18843\r",
      "37000\t19356\r",
      "38000\t19886\r",
      "39000\t20364\r",
      "40000\t20839\r",
      "41000\t21343\r",
      "42000\t21862\r",
      "43000\t22284\r",
      "44000\t22783\r",
      "45000\t23281\r",
      "46000\t23820\r",
      "47000\t24321\r",
      "48000\t24745\r",
      "49000\t25217\r",
      "50000\t25683\r",
      "51000\t26158\r",
      "52000\t26602\r",
      "53000\t27075\r",
      "54000\t27526\r",
      "55000\t27994\r",
      "56000\t28378\r",
      "57000\t28790\r",
      "58000\t29193\r",
      "59000\t29677\r",
      "60000\t30066\r",
      "61000\t30506\r",
      "62000\t30918\r",
      "63000\t31219\r",
      "64000\t31617\r",
      "65000\t32013\r",
      "65977\t32319\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "96\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 97\n",
      "Max. path length: 16\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "4000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [01:59<00:30, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "\r",
      "1000\r",
      "2000\r",
      "3000\r",
      "4000\r",
      "5000\r",
      "6000\r",
      "7000\r",
      "8000\r",
      "9000\r",
      "10000\r",
      "11000\r",
      "12000\r",
      "13000\r",
      "14000\r",
      "15000\r",
      "16000\r",
      "17000\r",
      "18000\r",
      "19000\r",
      "20000\r",
      "21000\r",
      "22000\r",
      "23000\r",
      "24000\r",
      "25000\r",
      "26000\r",
      "27000\r",
      "28000\r",
      "29000\r",
      "30000\r",
      "31000\r",
      "32000\r",
      "33000\r",
      "34000\r",
      "35000\r",
      "36000\r",
      "37000\r",
      "38000\r",
      "39000\r",
      "40000\r",
      "41000\r",
      "42000\r",
      "43000\r",
      "44000\r",
      "45000\r",
      "46000\r",
      "47000\r",
      "48000\r",
      "49000\r",
      "50000\r",
      "51000\r",
      "52000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1793 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "\r",
      "1000\t783\r",
      "2000\t1407\r",
      "3000\t2056\r",
      "4000\t2723\r",
      "5000\t3370\r",
      "6000\t3755\r",
      "7000\t4176\r",
      "8000\t4717\r",
      "9000\t5310\r",
      "10000\t5924\r",
      "11000\t6436\r",
      "12000\t6983\r",
      "13000\t7498\r",
      "14000\t7963\r",
      "15000\t8540\r",
      "16000\t9079\r",
      "17000\t9571\r",
      "18000\t9993\r",
      "19000\t10583\r",
      "20000\t11127\r",
      "21000\t11399\r",
      "22000\t11736\r",
      "23000\t12155\r",
      "24000\t12564\r",
      "25000\t13001\r",
      "26000\t13532\r",
      "27000\t14153\r",
      "28000\t14683\r",
      "29000\t15208\r",
      "30000\t15630\r",
      "31000\t16050\r",
      "32000\t16497\r",
      "33000\t16993\r",
      "34000\t17559\r",
      "35000\t18099\r",
      "36000\t18624\r",
      "37000\t19177\r",
      "38000\t19660\r",
      "39000\t20127\r",
      "40000\t20624\r",
      "41000\t21165\r",
      "42000\t21631\r",
      "43000\t22087\r",
      "44000\t22599\r",
      "45000\t23122\r",
      "46000\t23628\r",
      "47000\t24078\r",
      "48000\t24544\r",
      "49000\t25002\r",
      "50000\t25475\r",
      "51000\t25932\r",
      "52000\t26382\r",
      "53000\t26859\r",
      "54000\t27296\r",
      "55000\t27749\r",
      "56000\t28139\r",
      "57000\t28532\r",
      "58000\t29006\r",
      "59000\t29416\r",
      "60000\t29863\r",
      "61000\t30286\r",
      "62000\t30594\r",
      "63000\t30989\r",
      "64000\t31382\r",
      "65000\t31718\r",
      "65104\t31742\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "102\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 103\n",
      "Max. path length: 20\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "5000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [02:15<00:15, 15.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train-tree-tagger -cl 2 -dtg 0.50 -sw 1.00 -ecw 0.15 -atg 1.20 lexicon.txt open_class.txt corpus_train.txt model_oc\n",
      "\n",
      "\treading the lexicon ...\n",
      "\t\treading the tagset ...\n",
      "\t\treading the lemmas ...\n",
      "\t\treading the entries ...\n",
      "\t\tsorting the lexicon ...\n",
      "\t\treading the open class tags ...\n",
      "\tcalculating tag frequencies ...\n",
      "\r",
      "1000\r",
      "2000\r",
      "3000\r",
      "4000\r",
      "5000\r",
      "6000\r",
      "7000\r",
      "8000\r",
      "9000\r",
      "10000\r",
      "11000\r",
      "12000\r",
      "13000\r",
      "14000\r",
      "15000\r",
      "16000\r",
      "17000\r",
      "18000\r",
      "19000\r",
      "20000\r",
      "21000\r",
      "22000\r",
      "23000\r",
      "24000\r",
      "25000\r",
      "26000\r",
      "27000\r",
      "28000\r",
      "29000\r",
      "30000\r",
      "31000\r",
      "32000\r",
      "33000\r",
      "34000\r",
      "35000\r",
      "36000\r",
      "37000\r",
      "38000\r",
      "39000\r",
      "40000\r",
      "41000\r",
      "42000\r",
      "43000\r",
      "44000\r",
      "45000\r",
      "46000\r",
      "47000\r",
      "48000\r",
      "49000\r",
      "50000\r",
      "51000\r",
      "52000\r",
      "53000\tmaking affix tree ...\n",
      "prefix lexicon: 807 nodes\n",
      "suffix lexicon: 1798 nodes\n",
      "\treading classes ...\n",
      "\tmaking ngram table ...\n",
      "\r",
      "1000\t787\r",
      "2000\t1482\r",
      "3000\t2240\r",
      "4000\t2966\r",
      "5000\t3696\r",
      "6000\t4283\r",
      "7000\t4833\r",
      "8000\t5201\r",
      "9000\t5790\r",
      "10000\t6381\r",
      "11000\t6948\r",
      "12000\t7454\r",
      "13000\t7973\r",
      "14000\t8519\r",
      "15000\t9016\r",
      "16000\t9529\r",
      "17000\t10078\r",
      "18000\t10507\r",
      "19000\t10962\r",
      "20000\t11609\r",
      "21000\t12023\r",
      "22000\t12281\r",
      "23000\t12713\r",
      "24000\t13101\r",
      "25000\t13523\r",
      "26000\t13955\r",
      "27000\t14524\r",
      "28000\t15123\r",
      "29000\t15640\r",
      "30000\t16077\r",
      "31000\t16487\r",
      "32000\t16936\r",
      "33000\t17418\r",
      "34000\t17937\r",
      "35000\t18491\r",
      "36000\t19006\r",
      "37000\t19532\r",
      "38000\t20045\r",
      "39000\t20523\r",
      "40000\t21009\r",
      "41000\t21522\r",
      "42000\t22053\r",
      "43000\t22484\r",
      "44000\t22986\r",
      "45000\t23485\r",
      "46000\t24012\r",
      "47000\t24500\r",
      "48000\t24903\r",
      "49000\t25405\r",
      "50000\t25871\r",
      "51000\t26347\r",
      "52000\t26790\r",
      "53000\t27274\r",
      "54000\t27692\r",
      "55000\t28170\r",
      "56000\t28573\r",
      "57000\t28993\r",
      "58000\t29386\r",
      "59000\t29853\r",
      "60000\t30251\r",
      "61000\t30667\r",
      "62000\t31085\r",
      "63000\t31378\r",
      "64000\t31786\r",
      "65000\t32112\r",
      "65696\t32391\n",
      "finished.\n",
      "\tmaking decision tree ...\n",
      "86\tsaving parameters ...\n",
      "\n",
      "Number of nodes: 87\n",
      "Max. path length: 15\n",
      "\n",
      "done.\n",
      "\treading parameters ...\n",
      "\ttagging ...\n",
      "5000\t finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [02:32<00:00, 16.12s/it]\n"
     ]
    }
   ],
   "source": [
    "mistake_score = []\n",
    "\n",
    "for i in tqdm(range(len(cross_val_folds))):\n",
    "    !rm corpus_train.txt\n",
    "    !rm corpus_test.txt\n",
    "    j = len(cross_val_folds) - 1\n",
    "    while j != -1:\n",
    "        if j == i:\n",
    "            for sent in cross_val_folds[i]:\n",
    "                with open('corpus_train.txt', 'a', encoding='utf-8') as fd_test:\n",
    "                    fd_test.write('\\n' + '\\n'.join(sent[1].split()))\n",
    "        else:\n",
    "            for sent in cross_val_folds[j]:\n",
    "                with open('corpus_train.txt', 'a', encoding='utf-8') as fd_train:\n",
    "                    fd_train.write(sent[0])\n",
    "        j -= 1\n",
    "    !./bin/train-tree-tagger lexicon.txt open_class.txt corpus_train.txt model_oc\n",
    "    !./bin/tree-tagger model_oc corpus_test.txt output.txt\n",
    "    mistake_score.append(mistake_finder(\"output.txt\", cross_val_folds[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w3PkkFRQTmAD"
   },
   "source": [
    "**Усредним ошибку по каждому фолду и посмотрим на общую ошибку. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1560540351325,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "RONZaD6iTmAE",
    "outputId": "a1a98e94-b534-46bb-bb27-b0f6c972b82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 1 \t score:  0.9009397024275646\n",
      "fold # 2 \t score:  0.9008631964425844\n",
      "fold # 3 \t score:  0.8978717882169738\n",
      "fold # 4 \t score:  0.8903091169949132\n",
      "fold # 5 \t score:  0.9130639836503694\n",
      "fold # 6 \t score:  0.8924028875902372\n",
      "fold # 7 \t score:  0.8730800323362975\n",
      "fold # 8 \t score:  0.8863717445594006\n",
      "fold # 9 \t score:  0.8763431069022036\n",
      "Total score:  0.8912882320866224\n",
      "Stanard Dev:  0.012198743724719265\n"
     ]
    }
   ],
   "source": [
    "folds_result = []\n",
    "\n",
    "for i in range(1, len(mistake_score)):\n",
    "    fold_result = np.mean(mistake_score[i][0])\n",
    "    print(\"fold #\", i, \"\\t score: \", fold_result)\n",
    "    folds_result.append(fold_result)\n",
    "    \n",
    "print(\"Total score: \", np.mean(folds_result[1:]))\n",
    "print(\"Stanard Dev: \", np.std(folds_result[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVuUqVh9kCVq"
   },
   "source": [
    "**Качество хороше достаточно хорошее и более-менее одинаковое во всех фолдах.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsS5i4K6TmAJ"
   },
   "source": [
    "**Посмотрим 25 слов с наиболее часто встречающимися ошибками классификации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1560541979911,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "ypTSVAaOTmAK",
    "outputId": "e48b76ed-eeb4-45eb-c9af-0b13f6dd4ab3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('В', 'PREP', 'NOUN'), 437),\n",
       " (('.', 'PNCT', 'SENT'), 388),\n",
       " (('Я', 'NPRO', 'NOUN'), 190),\n",
       " ((',', 'SENT', 'PNCT'), 135),\n",
       " (('Не', 'PRCL', 'NOUN'), 121),\n",
       " (('»', 'SENT', 'PNCT'), 100),\n",
       " ((':', 'PNCT', 'SENT'), 95),\n",
       " (('На', 'PREP', 'NOUN'), 94),\n",
       " (('Он', 'NPRO', 'NOUN'), 90),\n",
       " (('По', 'PREP', 'NOUN'), 77),\n",
       " (('Мы', 'NPRO', 'NOUN'), 77),\n",
       " (('С', 'PREP', 'NOUN'), 72),\n",
       " (('.', 'SENT', 'PNCT'), 63),\n",
       " (('Вы', 'NPRO', 'NOUN'), 58),\n",
       " (('И', 'CONJ', 'NOUN'), 57),\n",
       " ((',', 'PNCT', 'SENT'), 56),\n",
       " (('!', 'PNCT', 'SENT'), 56),\n",
       " (('А', 'CONJ', 'NOUN'), 54),\n",
       " (('Почему', 'ADVB', 'NOUN'), 53),\n",
       " ((')', 'SENT', 'PNCT'), 50),\n",
       " (('Но', 'CONJ', 'NOUN'), 46),\n",
       " (('»', 'PNCT', 'SENT'), 46),\n",
       " (('Она', 'NPRO', 'NOUN'), 46),\n",
       " (('Вот', 'PRCL', 'NOUN'), 44),\n",
       " (('…', 'PNCT', 'SENT'), 42)]"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MISTAKES.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecAOV3pikWK4"
   },
   "source": [
    "* 10 из 25 ошибок - проблема тэгов, связанных с пунктуацией. \n",
    "* Остальные ошибки - короткие слова  (местоимения, союзы, предлоги) почему-то всегда маркируются как существительные. Возможное объяснение: наиболее частая часть речи в тексте, и возможно, она просто ставится для нераспознанных слов как \"дефолтная\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-IE9GdRok9kj"
   },
   "source": [
    "### Сравниваем классификаторы\n",
    "\n",
    "При этом опустим знаки препинания, потому что они как-то слишком сильно смущают TreeTagger, с которым мы хотим его сравнить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcedA04bTmAV"
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2138,
     "status": "ok",
     "timestamp": 1560542551439,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "c5k4SD6iTmAb",
    "outputId": "f05c34ba-b676-4cd5-c3b9-4eaf2c3e9de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "pm2_mistakes = Counter()\n",
    "score = []\n",
    "print(len(cross_val_folds))\n",
    "for el in cross_val_folds[0]:\n",
    "    sent = el[2]\n",
    "    for word in sent:\n",
    "        if word[1][0] != 'PNCT' and word[1][0] != 'SENT':\n",
    "            analysis = morph.tag(word[0])[0].POS\n",
    "            if analysis == word[1][0]:\n",
    "                score.append(1)\n",
    "            else:\n",
    "                score.append(0)\n",
    "                pm2_mistakes.update([(word[0], analysis, word[1][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1560542553379,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "cc-WEH4UTmAg",
    "outputId": "bf45689c-2805-42d2-bed6-82db72b29dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pymorphy score:  0.8860546815335268\n"
     ]
    }
   ],
   "source": [
    "print(\"Pymorphy score: \", np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-GCwCRxrzjt"
   },
   "source": [
    "Посмотрим на 25 наиболее частотных ошибок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1560542558258,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "wfqqeNzzTmAl",
    "outputId": "d27a6b2b-187a-4b43-945e-b04049ef09a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('2007', None, 'NUMB'), 12),\n",
       " (('2', None, 'NUMB'), 10),\n",
       " (('of', None, 'LATN'), 10),\n",
       " (('5', None, 'NUMB'), 9),\n",
       " (('1', None, 'NUMB'), 9),\n",
       " (('10', None, 'NUMB'), 9),\n",
       " (('24', None, 'NUMB'), 9),\n",
       " (('11', None, 'NUMB'), 9),\n",
       " (('3', None, 'NUMB'), 9),\n",
       " (('20', None, 'NUMB'), 8),\n",
       " (('2010', None, 'NUMB'), 8),\n",
       " (('9', None, 'NUMB'), 8),\n",
       " (('2008', None, 'NUMB'), 8),\n",
       " (('также', 'CONJ', 'PRCL'), 8),\n",
       " (('2005', None, 'NUMB'), 8),\n",
       " (('ISBN', None, 'LATN'), 8),\n",
       " (('2009', None, 'NUMB'), 7),\n",
       " (('25', None, 'NUMB'), 6),\n",
       " (('4', None, 'NUMB'), 6),\n",
       " (('2006', None, 'NUMB'), 6),\n",
       " (('15', None, 'NUMB'), 6),\n",
       " (('the', None, 'LATN'), 6),\n",
       " (('2004', None, 'NUMB'), 6),\n",
       " (('1999', None, 'NUMB'), 6),\n",
       " (('2011', None, 'NUMB'), 5)]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm2_mistakes.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1560540398423,
     "user": {
      "displayName": "Кирилл Семёнов",
      "photoUrl": "",
      "userId": "10277171521798335065"
     },
     "user_tz": -180
    },
    "id": "_ow18tV3TmAs",
    "outputId": "1bc45c30-f905-42b2-c56b-1816a17f3111"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpencorporaTag('NUMB,intg')"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('1')[0].tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kqhd46nLTmAx"
   },
   "source": [
    "# Вывод:\n",
    "Абсолютное большинство ошибочных слов - числительные, оставшиеся примеры - латинские заимствования. Это, как и анализ ошибок TreeTagger'a, указывает на то, что сбой у этого классификатора происходит в \"маргинальных\" случаях - пунктуации, латинских словах, цифрах и т.д.\n",
    "В общем, TreeTagger хорош, но только на очищенных от \"мусора\" данных. При этом Pymorphy2 справляется и с этим \"мусором\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnQSyK-pTmAy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW3-Smirnova.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
